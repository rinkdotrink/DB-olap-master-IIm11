\section{Einleitung}\label{Einleitung}

%\newglossaryentry{EasyMock}{name=EasyMock,description={Test-Framework zur dynamischen Generierung von Mock Objekten}}
%\newglossaryentry{Dependency Injection}{name=Dependency Injection,description={Entwurfsmuster, um Abhängigkeiten zwischen Objekten zu %minimieren}}

%\newacronym{IDE}{IDE}{Integrated Development Environment}

Ziel dieses Projektes ist die Performance eines relationalen Datenbankmanagementsystems für bestimmte Datenbank-Konfigurationen zu messen und auszuwerten. Eine Datenbank-Konfiguration, im Folgenden kurz Konfiguration genannt, ergibt sich aus den Anforderungen, die eine Anwendung an das DBMS bzw. die konkrete Datenbank stellt. 
Es ergibt sich die Frage, für welche konkrete Anforderung welche konkrete Konfiguration gewählt werden sollte? Um diese Frage zu beantworten, sind mehrere Schritte nötig. Es werden Anforderungen aus vier verschiedenen praktischen Anwendungsfällen gesammelt. Es wird dann eines der bekanntesten relationalen DBMS exemplarisch ausgewählt. Welches es genau sein wird, ist für die Aufgabe zweitrangig. Dann wird ein Anwendungsfall aus den vier Anwendungsfällen ausgewählt. Für ihn wird im DBMS ein ERD angefertigt, dass die Tabellen beschreibt. Um die Performance für die vier Anwendungsfälle zu messen, werden die Tabellen aus dem ERD in unterschiedlich konfigurierten Datenbanken getestet. Aus Gründen der Einfachheit und Übersichtlichkeit wird dieses eine ERD auch für die Konfigurationen der drei anderen Andwendungsfälle genutzt. Weil es in diesem Projekt um die Performance verschiedener Konfigurationen geht, muss das ERD nicht zu jedem Anwendungsfall passen. Um die Performance zu messen, müssen die Tabellen vorher mit Testdaten befüllt werden. Dazu ist ein Datengenerator zu erstellen. Er generiert die Testdaten für die Tabellen. Die konkreten Anforderungen, die an den Datengenerator gestellt werden, müssen analysiert werden. Dann wird der Generator entworfen, implementiert und getestet. Für den Datengenerator wird ein Build Mangagement Tool eingesetzt sowie Frameworks für Dependency Injection und zum Testen der Anwendung. Die Zeiten für das Befüllen der Tabellen mit dem Generator werden gemessen und ausgewertet. Ebenso werden für jede der vier Konfigurationen verschiedene Queries auf den mit Testdaten befüllten Tabellen gefahren und die Antwortzeiten gemessen. Die Messungen erfolgen alle auf einem Referenzsystem. So können verschiedene Konfigurationen über ihre Performancewerte miteinander verglichen werden.